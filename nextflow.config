/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nfcore/dnaseqaln Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/
nextflow.enable.moduleBinaries = true
// Global default params, used in configs
manifest {
    name            = 'Variant Call'
    author          = """Guanqiao Feng"""
    homePage        = 'https://github.com/icgc-argo-workflows/variant_call_monstar'
    description     = """ICGC-ARGO analysis workflow for Variant Call for Monstar Project"""
    mainScript      = 'main.nf'
    nextflowVersion = '!>=22.10.1'
    version         = '1.0dev'
    doi             = ''
}

params {

    // TODO nf-core: Specify your pipeline's command line flags
    // Input options
    study_id = null
    analysis_id = null
    tools = "cleanup"
    local_mode = false
    reference_fasta = null
    reference_fasta_secondary = null
    samplesheet = null

    fasta_url = 'https://swengbioinfo.blob.core.windows.net/genomics-public-data/reference-genome/GRCh38_hla_decoy_ebv/GRCh38_hla_decoy_ebv.fa.gz'
    fai_url = 'https://swengbioinfo.blob.core.windows.net/genomics-public-data/reference-genome/GRCh38_hla_decoy_ebv/GRCh38_hla_decoy_ebv.fa.fai'
    chain_url = 'https://hgdownload.soe.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz'

    fasta_checksum = '3a72dfa0f5076103f2b1894ed3328e9247099a629256c98679f00e30a9fb35e4'
    fai_checksum = 'f361f004bdae5ca68d632458b01a3848d02834ac7176f378e177344d148a6a6d'
    chain_checksum = '5c0598e500ceb5a78c73086929e8ef993aec309bcafb595139b53d440b125a1d'

    api_token                  = null
    api_download_token         = null
    api_upload_token           = null
    song_url                   = null
    score_url                  = null
    song_url_download          = null
    score_url_download         = null
    song_url_upload            = null
    score_url_upload           = null
    transport_parallel         = null
    transport_mem              = null
    song_container             = null
    song_container_version     = null
    score_container            = null
    score_container_version    = '5.10.0'

    // Boilerplate options
    outdir                     = "out"
    publish_dir_mode           = 'symlink'
    tracedir                   = "${params.outdir}/pipeline_info"

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'

}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'
// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'


profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        conda.enabled          = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        docker.registry = 'quay.io'
        docker.runOptions = '-u \$(id -u):\$(id -g)'
    }
    arm {
        docker.runOptions = '-u $(id -u):$(id -g) --platform=linux/amd64'
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        singularity.engineOptions = '-s'
    }
    test               { includeConfig 'conf/test.config'           }
    rdpc               { includeConfig 'conf/repos/rdpc.config'     }
    rdpc_qa            { includeConfig 'conf/repos/rdpc_qa.config'  }
    rdpc_dev           { includeConfig 'conf/repos/rdpc_dev.config' }
}


// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}


// Load modules.config for DSL2 module specific options
// includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
